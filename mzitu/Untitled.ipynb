{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "\n",
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = {'User-Agent':\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.101 Safari/537.36\",\n",
    "           'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "           'Accept-Encoding':'gzip, deflate',\n",
    "           'Accept-Language':'zh-CN,zh;q=0.8',\n",
    "           'Connection':'keep-alive',\n",
    "           'Cookie':'Hm_lvt_dbc355aef238b6c32b43eacbbf161c3c=1503069614,1503070371,1503070382,1503070882; Hm_lpvt_dbc355aef238b6c32b43eacbbf161c3c=1503072603',\n",
    "           'Host':'www.mzitu.com',\n",
    "           'Upgrade-Insecure-Requests':'1'\n",
    "           }\n",
    "proxie = { \n",
    "        'http':'http://222.175.44.23:8081'\n",
    "    }\n",
    "\n",
    "all_url = 'http://www.mzitu.com/all/'\n",
    "start_html = session.get(all_url,  headers=headers, verify=False, proxies=proxie)  \n",
    "soup = BeautifulSoup(start_html.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "这个网页已经爬过了\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "http://www.mzitu.com/95520上数据爬取完成\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "http://www.mzitu.com/95488上数据爬取完成\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "http://www.mzitu.com/95461上数据爬取完成\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "http://www.mzitu.com/95399上数据爬取完成\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "http://www.mzitu.com/95344上数据爬取完成\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "http://www.mzitu.com/95318上数据爬取完成\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "http://www.mzitu.com/95284上数据爬取完成\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "出现问题\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "http://www.mzitu.com/95240上数据爬取完成\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n",
      "存储成功\n"
     ]
    }
   ],
   "source": [
    "all_a = soup.find('div', class_='all').find_all('a')\n",
    "\n",
    "for a in all_a:\n",
    "    headers['Referer'] = all_url\n",
    "    title = a.get_text()\n",
    "    href = a['href']\n",
    "    if href not in url_done:\n",
    "        url_done.append(href)\n",
    "    else:\n",
    "        print('这个网页已经爬过了')\n",
    "        continue\n",
    "    path = str(title).strip()\n",
    "    os.makedirs(os.path.join(\"/media/jesse/My Passport/mzitu\", path))\n",
    "    os.chdir(\"/media/jesse/My Passport/mzitu/\"+path)\n",
    "    try:\n",
    "        html = requests.get(href, headers=headers)\n",
    "        if html.status_code // 100 == 2:\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "    except:\n",
    "        continue\n",
    "    html_soup = BeautifulSoup(html.text, 'lxml')\n",
    "    max_span = html_soup.find('div', class_='pagenavi').find_all('span')[-2].get_text()\n",
    "    headers['Referer'] = href\n",
    "    \n",
    "    for page in range(1, int(max_span)+1):\n",
    "        page_url = href + '/' + str(page)\n",
    "        try:\n",
    "            img_html = requests.get(page_url, headers=headers, verify=False, proxies=proxie)\n",
    "            if html.status_code // 100 == 2:\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "        img_soup = BeautifulSoup(img_html.text, 'lxml')\n",
    "        img_url = img_soup.find('div', class_='main-image').find('img')['src']\n",
    "        name = img_url[-9:-4]\n",
    "        headers['Referer'] = page_url\n",
    "        try:\n",
    "            img = requests.get(img_url, headers=headers, verify=False, proxies=proxie)\n",
    "            if img.status_code // 100 == 2:\n",
    "                f = open(name+'.jpg', 'ab')\n",
    "                f.write(img.content)\n",
    "                f.close()\n",
    "                print('存储成功')\n",
    "            else:\n",
    "                print('出现问题')\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(href+'上数据爬取完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_undone.append(url_done[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_undone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_undone = ['http://www.mzitu.com/99889',\n",
    "              'http://www.mzitu.com/98751',\n",
    "              'http://www.mzitu.com/97719',\n",
    "              'http://www.mzitu.com/97549',\n",
    "              'http://www.mzitu.com/97412',\n",
    "              'http://www.mzitu.com/96731']"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
